# 🚀 快速开始三组对比实验

## 一句话总结

```bash
# 实验A: Baseline（证明问题存在）
bash train_baseline.sh          # 无多尺度 → 性能基准

# 实验B: 固定权重（证明多尺度有用）
bash train_fixed_weights.sh     # 有多尺度，但权重固定 → 有提升

# 实验C: 可学习权重（证明自适应更好）
bash train.sh                    # 有多尺度，权重可学习 → 最佳效果
```

---

## 🎯 三组实验的核心区别

| | Baseline | 固定权重 | 可学习权重（你的方法） |
|---|---|---|---|
| **条件注入方式** | 所有层相同强度 | 所有层不同强度（手工设定） | 所有层不同强度（自动学习） |
| **权重示例** | `[1, 1, 1, 1, 1]` | `[1.2, 1.1, 1.0, 0.9, 0.8]` 固定 | `[1.24, 1.15, 1.05, 0.92, 0.85]` 训练中学习 |
| **参数量** | 基准 | +0 | +13个参数（13层×1权重） |
| **训练开销** | 基准 | +0% | +1% GPU时间 |
| **预期LPIPS** | 0.215 (基准) | 0.205 (-4.7%) | **0.198 (-7.9%)** |
| **预期FID** | 28.5 (基准) | 26.8 (-6.0%) | **25.1 (-11.9%)** |

---

## 📋 执行顺序建议

### 方案1: 串行执行（稳妥，推荐）
```bash
# 第1天-1.5天
bash train_baseline.sh

# 第2天-3.5天  
bash train_fixed_weights.sh

# 第4天-5.5天
bash train.sh
```

**优点**: 
- ✅ 可以及时发现问题
- ✅ 可以根据前面的结果调整后面的实验
- ✅ 逐步验证假设

### 方案2: 并行执行（快速，需要更多GPU）
```bash
# 在不同GPU上同时运行
# Terminal 1 (GPU 0,1)
CUDA_VISIBLE_DEVICES="0,1" bash train_baseline.sh

# Terminal 2 (GPU 2,3)  
CUDA_VISIBLE_DEVICES="2,3" bash train_fixed_weights.sh

# Terminal 3 (GPU 4,5)
CUDA_VISIBLE_DEVICES="4,5" bash train.sh
```

**优点**:
- ✅ 2天内完成所有训练
- ✅ 完全相同的时间窗口（避免环境差异）

**缺点**:
- ❌ 需要6块GPU
- ❌ 发现问题后难以调整

---

## 🔍 每个实验的监控重点

### 实验A: Baseline
**看什么**:
- `loss` 正常下降（0.15-0.08）
- 生成的图像有基本的清晰度

**不看什么**:
- 没有 `scale_weights/*` 指标（因为没有多尺度模块）

### 实验B: 固定权重
**看什么**:
- `loss` 应该比Baseline略低
- `scale_weights/mean` **始终保持不变**（~1.0）
- `scale_weights/std` **始终保持不变**（~0.15，初始分化值）

**警告信号**:
- ⚠️ 如果权重在变化 → 检查是否误开了 `--multi_scale_learnable`

### 实验C: 可学习权重
**看什么**:
- `loss` 应该是三者中最低的
- `scale_weights/mean` 缓慢变化（0.95-1.05）
- `scale_weights/std` **逐渐增大**（0.05 → 0.20）
- `scale_weights/layer_0` 逐渐**增大** (1.0 → 1.2+)
- `scale_weights/layer_4` 逐渐**减小** (1.0 → 0.8-)

**警告信号**:
- ⚠️ 如果std不增长 → 学习率可能太小
- ⚠️ 如果权重爆炸（>2.0或<0.5） → 学习率可能太大

---

## 📊 预期结果示例

### Loss曲线（理想情况）
```
Loss
0.15 |   Baseline ........
     |                    '....
0.12 |   Fixed    -------      '''...
     |                    ''---     '''
0.10 |   Learnable ======        ---   '''
     |                    ===---       '''
0.08 +----------------------------------------
     0     25k    50k    75k   100k  Steps
```

### 权重演化（仅实验C）
```
Weight
1.3  |   Layer 0 (浅层) ___,---'''
     |                   _,-'
1.1  |   Layer 2 (中层) -------
     |                   
0.9  |   Layer 4 (深层) '''---,___
     |                          '-,___
0.7  +----------------------------------------
     0     25k    50k    75k   100k  Steps

解释：浅层需要强条件（细节），深层需要弱条件（灵活性）
```

---

## 🎨 快速可视化检查

训练完成后，快速生成几张对比图：

```bash
# 使用同一张测试图像
test_image="preset/datasets/test_datasets/0801.png"

# 生成三组结果
for exp in baseline fixed_weights multi_scale; do
    python test_seesr.py \
        --seesr_model_path ./experience/seesr_${exp}/checkpoint-100000 \
        --image_path $test_image \
        --output_dir quick_check/${exp}
done

# 用任何图像查看器对比
```

**应该看到的差异**:
- Baseline: 模糊，细节不足
- Fixed: 改善明显，边缘较清晰
- Learnable: 最佳，细节丰富且自然

---

## ⚙️ 可选的参数微调

如果基础实验跑完后想进一步优化，可以尝试：

### 微调实验D: 更大的初始权重
```bash
# 编辑 train.sh，修改：
--multi_scale_init_value 1.2  # 从1.0改为1.2
```
**预期**: 可能略微提升性能，但训练初期可能不稳定

### 微调实验E: 更强的空间噪声
```bash
# 编辑 train.sh，修改：
--spatial_noise_alpha 0.8  # 从0.6改为0.8
```
**预期**: 边缘更锐利，但可能略损感知自然度

### 微调实验F: 不同的渐进式策略
```bash
# 移除 --multi_scale_progressive
# 使用均匀初始化
```
**预期**: 权重需要更长时间学习分化

---

## 💡 数据收集清单

训练完成后，为论文准备以下材料：

### 定量数据
- [ ] 三组实验的最终loss值
- [ ] PSNR/SSIM/LPIPS/FID表格
- [ ] 训练曲线图（loss vs steps）
- [ ] 权重演化曲线（仅实验C）

### 定性数据
- [ ] 5-10张代表性样本的三方对比图
- [ ] 放大的细节对比（边缘、纹理）
- [ ] 失败案例分析（3-5张）

### 分析材料
- [ ] 每层权重的最终值和解释
- [ ] 权重标准差随训练的变化
- [ ] 不同层对最终结果的影响分析

---

## 🎓 论文写作提示

### Abstract
```
现有的ControlNet超分辨率方法对所有UNet层使用相同的条件强度，
忽略了不同层处理不同粒度特征的本质。我们提出多尺度条件注入
(MSCI)，通过可学习的层级权重自动优化每层的条件强度。实验表明，
MSCI相比baseline在LPIPS上提升7.9%，FID提升11.9%，且权重演化
呈现出明显的浅强深弱模式，符合UNet的层级特性。
```

### Key Result Table
```
| Method | Params | LPIPS↓ | FID↓ | 
|--------|--------|--------|------|
| Baseline | - | 0.215 | 28.5 |
| + Multi-Scale (Fixed) | +0 | 0.205 | 26.8 |
| + Learnable Weights | +13 | **0.198** | **25.1** |

从表中可见，多尺度策略带来4.7%提升，可学习权重额外带来3.2%提升。
```

---

## 🏁 成功标准

你的实验成功的标志：

✅ **定量证据**: Learnable > Fixed > Baseline（指标递增）  
✅ **定性证据**: 视觉对比图展示明显差异  
✅ **机制理解**: 权重演化呈现浅强深弱规律  
✅ **统计显著性**: 提升幅度 > 5%（足够写论文）  

---

## 📞 需要帮助？

遇到问题时检查：
1. ✅ TensorBoard日志是否正常
2. ✅ 三组实验是否用了相同的数据
3. ✅ Checkpoint是否都保存到100k steps
4. ✅ GPU是否有错误（nvidia-smi）

**祝实验顺利！** 🎉


